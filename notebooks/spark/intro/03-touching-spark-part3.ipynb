{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"https://www.quantiaconsulting.com/logos/quantia_logo_orizz.png\" alt=\"Databricks Learning\" style=\"width: 600px; height: 240px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![Spark Logo Tiny](https://www.quantiaconsulting.com/logos/logo_spark_tiny.png) Touching Spark - Part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Let's start again by creating a new SparkSession.\n",
    "\n",
    "Note that we are working in a notebook environment, each notebook runs its own spark session..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import qcutils\n",
    "from pyspark.sql import SparkSession\n",
    "import boto3\n",
    "import io\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "baseUri = \"s3a://quantia-master/training/\"\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.amazonaws:aws-java-sdk:1.7.4,org.apache.hadoop:hadoop-aws:2.7.5 pyspark-shell'\n",
    "\n",
    "spark = (SparkSession.builder \n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"test\")\n",
    "    .getOrCreate()\n",
    "        )\n",
    "qcutils.init_spark_session(spark)\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ![Spark Logo Tiny](https://www.quantiaconsulting.com/logos/logo_spark_tiny.png) Partitioning\n",
    "\n",
    "A Partition is a logical chunk of a large data set.\n",
    "\n",
    "Very often the data we are processing is separated into logical partitions (ie. payments from the same country, ads displayed for given cookie, etc). In Spark, the partitions can be distributed among nodes.\n",
    "\n",
    "Partitioning plays a key role in the parallelization task. Spark can run 1 concurrent task for every partition of an RDD/Dataframe/Dataset up to the number of cores in the cluster. \n",
    "\n",
    "The next section uses [**Pageviews By Seconds** data set](https://dumps.wikimedia.org/other/pagecounts-raw/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "  [\n",
    "    StructField(\"timestamp\", StringType(), False),\n",
    "    StructField(\"site\", StringType(), False),\n",
    "    StructField(\"requests\", IntegerType(), False)\n",
    "  ]\n",
    ")\n",
    "\n",
    "fileName = baseUri + \"wikipedia_pageviews_by_second.tsv\"\n",
    "\n",
    "initialDF = (spark.read\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"sep\", \"\\t\")\n",
    "  .schema(schema)\n",
    "  .csv(fileName)\n",
    ")\n",
    "\n",
    "initialDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see below that our data consists of...\n",
    "* when the record was created\n",
    "* the site (mobile or desktop) \n",
    "* and the number of requests\n",
    "\n",
    "For every second of the day, there are two records, one for the mobile version of the site and one for desktop version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitions vs Slots\n",
    "### Slots/Cores\n",
    "\n",
    "In most cases, if you created your cluster, you should know how many cores you have.\n",
    "\n",
    "However, to check programatically, you can use `SparkContext.defaultParallelism`\n",
    "\n",
    "For more information, see the doc <a href=\"https://spark.apache.org/docs/latest/configuration.html#execution-behavior\" target=\"_blank\">Spark Configuration, Execution Behavior</a>\n",
    "> For operations like parallelize with no parent RDDs, it depends on the cluster manager:\n",
    "> * Local mode: number of cores on the local machine\n",
    "> * Mesos fine grained mode: 8\n",
    "> * **Others: total number of cores on all executor nodes or 2, whichever is larger**\n",
    "\n",
    "**Note:** In Spark API the term **core** meaning a thread available for parallel execution. In the next sections, we will refer to it as **slot** to avoid confusion with the number of cores in the underlying CPU(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = spark.sparkContext.defaultParallelism\n",
    "\n",
    "print(\"You have {} cores, or slots.\".format(cores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitions\n",
    "\n",
    "* The second 1/2 of this question is how many partitions of data do I have?\n",
    "* With that we have a question:\n",
    "  0. Why do I have that many?\n",
    "\n",
    "If our goal is to process all our data (say 1M records) in parallel, we need to divide that data up.\n",
    "\n",
    "If I have 8 **slots** for parallel execution, it would stand to reason that I want 1M / 8 or 125,000 records per partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start answering the question:\n",
    "* takes the `initialDF`\n",
    "* converts it to an `RDD`\n",
    "* and then asks the `RDD` for the number of partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = initialDF.rdd.getNumPartitions()\n",
    "print(\"Partitions: {0:,}\".format( partitions ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is **NOT** coincidental that we have **8 slots** and **8 partitions**\n",
    "* Starting from Spark 2.0 a lot of optimizations have been added to the readers.\n",
    "* Namely the readers looks at **the number of slots**, the **size of the data**, and makes a best guess at how many partitions **should be created**.\n",
    "* You can actually double the size of the data several times over and Spark will still read in **only 8 partitions**.\n",
    "* Eventually it will get so big that Spark will forgo optimization and read it in as 10 partitions, in that case.\n",
    "\n",
    "But 8 partitions and 8 slots is just too easy.\n",
    "  * Let's read in another copy of this same data.\n",
    "  * A parquet file that was saved in 9 partitions.\n",
    "  * This gives us an excuse to reason about the **relationship between slots and partitions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our initial DataFrame. We can let it infer the \n",
    "# schema because the cost for parquet files is really low.\n",
    "alternateDF = (spark.read\n",
    "  .parquet(baseUri + \"wikipedia_pageviews_by_second_9.parquet\")\n",
    ")\n",
    "\n",
    "print(\"Partitions: {0:,}\".format( alternateDF.rdd.getNumPartitions() ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have 9 partitions we have to ask...\n",
    "\n",
    "What is going to happen when I perform and action like `count()` **with 8 slots and 9 partitions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alternateDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #1:** Is it OK to let my code continue to run this way?\n",
    "\n",
    "**Question #2:** What if it was a **REALLY** big file that read in as **200 partitions** and we had **256 slots**?\n",
    "\n",
    "**Question #3:** What if it was a **REALLY** big file that read in as **200 partitions** and we had only **8 slots**, how long would it take compared to a dataset that has only 8 partitions?\n",
    "\n",
    "**Question #4:** Given the previous example (**200 partitions** vs **8 slots**) what are our options (given that we cannot increase the number of partitions)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Every Slot/Core\n",
    "\n",
    "With some very few exceptions, you always want the number of partitions to be **a factor of the number of slots**.\n",
    "\n",
    "That way **every slot is used**.\n",
    "\n",
    "That is, every slots is being assigned a task.\n",
    "\n",
    "With 9 partitions & 8 slots we just guaranteed our **job will take 2x** as long as it may need to.\n",
    "* 10 seconds, for example, to process the first 8.\n",
    "* Then as soon as one of the first 8 is done, another 10 seconds to process the last partition.\n",
    "\n",
    "With 5 partitions & 8 slots we are **under-utilizing three of the eight slots**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More or Less Partitions?\n",
    "\n",
    "As a **general guideline** it is advised that each partition (when cached) is roughly around 200MB.\n",
    "* Size on disk is not a good gauge. For example...\n",
    "* CSV files are large on disk but small in RAM - consider the string \"12345\" which is 10 bytes compared to the integer 12345 which is only 4 bytes.\n",
    "* Parquet files are highly compressed but uncompressed in RAM.\n",
    "* In a relational database... well... who knows?\n",
    "\n",
    "The **200 comes from** the real-world-experience of engineers and is **based largely on efficiency** and not so much resource limitations. \n",
    "\n",
    "On an executor with a reduced amount of RAM you might need to lower that.\n",
    "\n",
    "For example, at 8 partitions (corresponding to our max number of slots) & 200MB per partition\n",
    "* That will use roughly **1.5GB**\n",
    "* If you have transformations that balloon the data size (such as Natural Language Processing) you are sure to run into problems.\n",
    "\n",
    "**Question:** If I read in my data and it comes in as 10 partitions should I...\n",
    "* reduce my partitions down to 8 (1x number of slots)\n",
    "* or increase my partitions up to 16 (2x number of slots)\n",
    "\n",
    "**Answer:** It depends on the size of each partition\n",
    "* Read the data in. \n",
    "* Cache it. \n",
    "* Look at the size per partition.\n",
    "* If you are near or over 200MB consider increasing the number of partitions.\n",
    "* If you are under 200MB consider decreasing the number of partitions.\n",
    "\n",
    "The goal will **ALWAYS** be to use as few partitions as possible while maintaining at least 1 x number-of-slots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## repartition(n) or coalesce(n)\n",
    "\n",
    "We have two operations that can help address this problem: `repartition(n)` and `coalesce(n)`.\n",
    "\n",
    "If you look at the API docs, `coalesce(n)` is described like this:\n",
    "> Returns a new Dataset that has exactly numPartitions partitions, when fewer partitions are requested.<br/>\n",
    "> If a larger number of partitions is requested, it will stay at the current number of partitions.\n",
    "\n",
    "If you look at the API docs, `repartition(n)` is described like this:\n",
    "> Returns a new Dataset that has exactly numPartitions partitions.\n",
    "\n",
    "The key differences between the two are\n",
    "* `coalesce(n)` is a **narrow** transformation and can only be used to reduce the number of partitions.\n",
    "* `repartition(n)` is a **wide** transformation and can be used to reduce or increase the number of partitions.\n",
    "\n",
    "So, if I'm increasing the number of partitions I have only one choice: `repartition(n)`\n",
    "\n",
    "If I'm reducing the number of partitions I can use either one, so how do I decide?\n",
    "* First off, `coalesce(n)` is a **narrow** transformation and performs better because it avoids a shuffle.\n",
    "* However, `coalesce(n)` cannot guarantee even **distribution of records** across all partitions.\n",
    "* For example, with `coalesce(n)` you might end up with **a few partitions containing 80%** of all the data.\n",
    "* On the other hand, `repartition(n)` will give us a relatively **uniform distribution**.\n",
    "* And `repartition(n)` is a **wide** transformation meaning we have the added cost of a **shuffle operation**.\n",
    "\n",
    "In our case, we \"need\" to go form 5 partitions up to 8 partitions - our only option here is `repartition(n)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repartitionedDF = alternateDF.repartition(8)\n",
    "\n",
    "print(\"Partitions: {0:,}\".format( repartitionedDF.rdd.getNumPartitions() ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache, Again?\n",
    "\n",
    "We just balanced the number of partitions to the number of slots.\n",
    "\n",
    "Depending on the size of the data and the number of partitions, the shuffle operation can be fairly expensive (though necessary).\n",
    "\n",
    "Let's cache the result of the `repartition(n)` call..\n",
    "* Or more specifically, let's mark it for caching.\n",
    "* The actual cache will occur later once an action is performed\n",
    "* Or you could just execute a count to force materialization of the cache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spark.sql.shuffle.partitions\n",
    "\n",
    "The next problem has to do with a side effect of certain **wide** transformations.\n",
    "\n",
    "So far, we haven't hit any **wide** transformations other than `repartition(n)`\n",
    "* But eventually we will... \n",
    "* Let's illustrate the problem that we will **eventually** hit\n",
    "* We can do this by simply sorting our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(repartitionedDF\n",
    "  .orderBy(col(\"timestamp\"), col(\"site\")) # sort the data\n",
    "  .foreach(lambda x: None)               # litterally does nothing except trigger a job\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Detour\n",
    "Something isn't right here...\n",
    "* We only executed one action.\n",
    "* But two jobs were triggered.\n",
    "* If we look at the physical plan we can see the reason for the extra job.\n",
    "* The answer lies in the step **Exchange rangepartitioning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(repartitionedDF\n",
    "  .orderBy(col(\"timestamp\"), col(\"site\"))\n",
    "  .explain()\n",
    ")\n",
    "print(\"-\"*80)\n",
    "\n",
    "(repartitionedDF\n",
    "  .orderBy(col(\"timestamp\"), col(\"site\"))\n",
    "  .limit(3000000)\n",
    "  .explain()\n",
    ")\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(repartitionedDF\n",
    "  .orderBy(col(\"timestamp\"), col(\"site\")) # sort the data\n",
    "  .limit(100000)                           # only 100000 ....    \n",
    "  .foreach(lambda x: None)                # litterally does nothing except trigger a job\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Real Problem\n",
    "\n",
    "Back to the original issue...\n",
    "* Rerun the original job (below).\n",
    "* Take a look at the second job.\n",
    "* Look at the 3rd Stage.\n",
    "* Notice that it has 200 partitions!\n",
    "* And this is our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funkyDF = (repartitionedDF\n",
    "  .orderBy(col(\"timestamp\"), col(\"site\")) # sorts the data\n",
    ")                                         #\n",
    "funkyDF.foreach(lambda x: None)           # litterally does nothing except trigger a job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is the number of partitions we ended up with.\n",
    "\n",
    "Besides looking at the number of tasks in the final stage, we can simply print out the number of partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Partitions: {0:,}\".format( funkyDF.rdd.getNumPartitions() ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The engineers building Apache Spark chose a default value, 200, for the new partition size.\n",
    "\n",
    "After all our work to determine the right number of partitions they go and undo it on us.\n",
    "\n",
    "The value 200 is actually based on practical experience, attempting to account for the most common scenarios to date.\n",
    "\n",
    "Work is being done to intelligently determine this new value but that is still in progress.\n",
    "\n",
    "For now, we can tweak it with the configuration value `spark.sql.shuffle.partitions`\n",
    "\n",
    "We can see below that it is actually configured for 200 partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.get(\"spark.sql.shuffle.partitions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the config setting with the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we re-run our query, we will see that we end up with the 8 partitions we want post-shuffle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betterDF = (repartitionedDF\n",
    "  .orderBy(col(\"timestamp\"), col(\"site\")) # sort the data\n",
    ")                                         #\n",
    "betterDF.foreach(lambda x: None)          # litterally does nothing except trigger a job\n",
    "\n",
    "print(\"Partitions: {0:,}\".format( betterDF.rdd.getNumPartitions() ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ![Spark Logo Tiny](https://www.quantiaconsulting.com/logos/logo_spark_tiny.png)  Take Home Messages\n",
    "\n",
    "* Partitioning is vital in distributed computing and Big Data frameworks\n",
    "* The number of partitions should be related to the number of slots/cores of the system\n",
    "* A good trade-off between number of partitions and dimension of partitions improve the execution performance\n",
    "    * 200MB is, empirically, good partition dimension. \n",
    "    * Try to have fewer partition as possible (multiple of the number of slots) \n",
    "* Spark default configuration could not fit your needs\n",
    "    * 200 partitions as default could not fit your need, it really depends on use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ![Quantia Tiny Logo](https://www.quantiaconsulting.com/logos/quantia_logo_tiny.png) 2020 Quantia Consulting, srl. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "spark-hands-on",
  "notebookId": 4377518618624333
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
