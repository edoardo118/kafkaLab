{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 2px;\">\n",
    "  <img src=\"https://www.quantiaconsulting.com/logos/quantia_logo_orizz.png\" alt=\"Quantia Consulting\" style=\"width: 600px; height: 250px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery API (python) - exercise solution\n",
    "\n",
    "In this LAB notebook, you will try to use the [__BigQuery API__](https://googleapis.dev/python/bigquery/latest/index.html) for python.\n",
    "\n",
    "You will need to perform the following tasks:\n",
    "\n",
    "- create a new dataset\n",
    "- create a table (ingest the CSV file `people-with-dups.txt`)\n",
    "- query the table: extract the average salary for each gender\n",
    "- delete the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q google-cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q google-cloud-bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the python libraries\n",
    "\n",
    "import os\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the .json credentials and set the environment variable (TODO:student)\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"./credentials.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a BigQuery client object.\n",
    "\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: in order to avoid conflicts with your colleagues, please name the dataset_id by changing \"LAB_EXERCISE\" with \"\\<surname\\>_LAB_EXERCISE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset id: preparazione-lezione-gcp.LAB_EXERCISE\n"
     ]
    }
   ],
   "source": [
    "# Set the \"dataset_id\" and the \"location\" of the data\n",
    "\n",
    "dataset_id = \"{}.LAB_EXERCISE\".format(client.project)\n",
    "location = \"EU\"\n",
    "\n",
    "print(\"Dataset id: \" + dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a full Dataset object to send to the API.\n",
    "\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset preparazione-lezione-gcp.LAB_EXERCISE\n"
     ]
    }
   ],
   "source": [
    "# Send the dataset to the API for creation, with an explicit timeout.\n",
    "# Raises google.api_core.exceptions.Conflict if the Dataset already\n",
    "# exists within the project.\n",
    "\n",
    "dataset = client.create_dataset(dataset, timeout=30)  # Make an API request.\n",
    "print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a BigQuery table by ingesting CSV data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OPTION 1__: you can manually specify the table schema (see this [example](https://cloud.google.com/bigquery/docs/schemas#manually_specifying_schemas))\n",
    "\n",
    "Hint: the `:` character is a non-standard separator, you have to manage it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table id: preparazione-lezione-gcp.LAB_EXERCISE.PEOPLE_1\n"
     ]
    }
   ],
   "source": [
    "# Set \"table_id_1\" to the ID of the table to create\n",
    "\n",
    "table_id_1 = \"{}.{}.PEOPLE_1\".format(client.project, dataset.dataset_id)\n",
    "file_path = \"./people-with-dups.txt\"\n",
    "\n",
    "print(\"Table id: \" + table_id_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 103000 rows and 7 columns to preparazione-lezione-gcp.LAB_EXERCISE.PEOPLE_1\n"
     ]
    }
   ],
   "source": [
    "# Define the BigQuery job\n",
    "# DOCUMENTATION: https://googleapis.dev/python/bigquery/latest/generated/google.cloud.bigquery.job.LoadJobConfig.html\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    schema=[\n",
    "        bigquery.SchemaField(\"firstName\", \"STRING\", mode=\"NULLABLE\"),\n",
    "        bigquery.SchemaField(\"middleName\", \"STRING\", mode=\"NULLABLE\"),\n",
    "        bigquery.SchemaField(\"lastName\", \"STRING\", mode=\"NULLABLE\"),\n",
    "        bigquery.SchemaField(\"gender\", \"STRING\", mode=\"NULLABLE\"),\n",
    "        bigquery.SchemaField(\"birthDate\", \"TIMESTAMP\", mode=\"NULLABLE\"),\n",
    "        bigquery.SchemaField(\"salary\", \"INTEGER\", mode=\"NULLABLE\"),\n",
    "        bigquery.SchemaField(\"ssn\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    ],\n",
    "    skip_leading_rows=1,\n",
    "    field_delimiter=':',  # the ':' character is a non-standard separator --> must be specified\n",
    "    source_format=bigquery.SourceFormat.CSV, # The source file format (default CSV).\n",
    ")\n",
    "\n",
    "with open(file_path, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_id_1, job_config=job_config)\n",
    "\n",
    "job.result()  # Waits for the job to complete.\n",
    "\n",
    "table = client.get_table(table_id_1)  # Make an API request.\n",
    "print(\n",
    "    \"Loaded {} rows and {} columns to {}\".format(\n",
    "        table.num_rows, len(table.schema), table_id_1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__OPTION 2__: you can automatically infer the schema using the auto-detection (see this [example](https://cloud.google.com/bigquery/docs/schema-detect#loading_data_using_schema_auto-detection))\n",
    "\n",
    "Hint: the `:` character is a non-standard separator, you have to manage it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table id: preparazione-lezione-gcp.LAB_EXERCISE.PEOPLE_2\n"
     ]
    }
   ],
   "source": [
    "# Set \"table_id_2\" to the ID of the table to create\n",
    "\n",
    "table_id_2 = \"{}.{}.PEOPLE_2\".format(client.project, dataset.dataset_id)\n",
    "file_path = \"./people-with-dups.txt\"\n",
    "\n",
    "print(\"Table id: \" + table_id_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 103000 rows and 7 columns to preparazione-lezione-gcp.LAB_EXERCISE.PEOPLE_2\n"
     ]
    }
   ],
   "source": [
    "# Define the BigQuery job\n",
    "# DOCUMENTATION: https://googleapis.dev/python/bigquery/latest/generated/google.cloud.bigquery.job.LoadJobConfig.html\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    autodetect=True, # schema autodetection\n",
    "    field_delimiter=':',  # the ':' character is a non-standard separator --> must be specified\n",
    "    source_format=bigquery.SourceFormat.CSV, # The source file format (default CSV).\n",
    ")\n",
    "\n",
    "with open(file_path, \"rb\") as source_file:\n",
    "    job = client.load_table_from_file(source_file, table_id_2, job_config=job_config)\n",
    "\n",
    "job.result()  # Waits for the job to complete.\n",
    "\n",
    "table = client.get_table(table_id_2)  # Make an API request.\n",
    "print(\n",
    "    \"Loaded {} rows and {} columns to {}\".format(\n",
    "        table.num_rows, len(table.schema), table_id_2\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a query\n",
    "\n",
    "You will have to write a query which extracts the average salary for each gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will query both the tables, to show that the results are identical.\n",
    "\n",
    "query_1 = \"\"\"\n",
    "    SELECT gender, AVG(salary)\n",
    "    FROM `\"\"\" + table_id_1 + \"\"\"`\n",
    "    GROUP BY gender\n",
    "\"\"\"\n",
    "\n",
    "query_2 = \"\"\"\n",
    "    SELECT gender, AVG(salary)\n",
    "    FROM `\"\"\" + table_id_2 + \"\"\"`\n",
    "    GROUP BY gender\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the queries\n",
    "\n",
    "query_job_1 = client.query(query_1)\n",
    "\n",
    "query_job_2= client.query(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query_1 data:\n",
      "gender=F, avg_salary=155504.28803229696\n",
      "gender=M, avg_salary=155142.32038929235\n",
      "\n",
      "The query_2 data:\n",
      "gender=F, avg_salary=155504.28803229696\n",
      "gender=M, avg_salary=155142.32038929235\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "\n",
    "print(\"The query_1 data:\")\n",
    "for row in query_job_1:\n",
    "    # Row values can be accessed by field name or index.\n",
    "    print(\"gender={}, avg_salary={}\".format(row[0], row[1]))\n",
    "    \n",
    "print(\"\\nThe query_2 data:\")\n",
    "for row in query_job_2:\n",
    "    # Row values can be accessed by field name or index.\n",
    "    print(\"gender={}, avg_salary={}\".format(row[0], row[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted dataset 'preparazione-lezione-gcp.LAB_EXERCISE'.\n"
     ]
    }
   ],
   "source": [
    "# Delete the dataset\n",
    "\n",
    "client.delete_dataset(\n",
    "    dataset_id, delete_contents=True, not_found_ok=True\n",
    ")\n",
    "\n",
    "print(\"Deleted dataset '{}'.\".format(dataset_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ![Quantia Tiny Logo](https://www.quantiaconsulting.com/logos/quantia_logo_tiny.png) 2021 Quantia Consulting, srl. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
