{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 2px;\">\n",
    "  <img src=\"https://www.quantiaconsulting.com/logos/quantia_logo_orizz.png\" alt=\"Quantia Consulting\" style=\"width: 600px; height: 250px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Corrupt/bad Records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Let's start importing libraries and creating useful variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "\n",
    "import os\n",
    "import qcutils\n",
    "from pyspark.sql import SparkSession\n",
    "import boto3\n",
    "import io\n",
    "import pandas\n",
    "import s3fs\n",
    "\n",
    "baseUri = \"/home/jovyan/materials/local-data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Malformed Lines\n",
    "\n",
    "Let's try to read a pipe-separated file and let the system infer data-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodDF = pandas.read_csv(baseUri+\"good.csv\", sep=\"|\")\n",
    "goodDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No problem here, but what if the file contains lines with fewer fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badDF = pandas.read_csv(baseUri+\"bad-fewer.csv\", sep=\"|\")\n",
    "badDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No problem from programmatically point of view, lines with too few fields will have `NA` values filled in the trailing fields\n",
    "\n",
    "Unfortunaltely, the resulting DataFrame lose its meaning....\n",
    "\n",
    "...but what about lines with more fileds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badDF = pandas.read_csv(baseUri+\"bad-more.csv\", sep=\"|\")\n",
    "badDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system raise an error by default\n",
    "\n",
    "Let's try to play with parameters.\n",
    "\n",
    "`error_bad_lines`\n",
    ">boolean, default True\n",
    ">\n",
    ">Lines with too many fields (e.g. a csv line with too many commas) will by default cause an exception to be raised, and no >DataFrame will be returned. If False, then these “bad lines” will dropped from the DataFrame that is returned. See bad lines below.\n",
    "\n",
    "`warn_bad_lines`\n",
    ">boolean, default True\n",
    ">\n",
    ">If error_bad_lines is False, and warn_bad_lines is True, a warning for each “bad line” will be output.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badDF2 = pandas.read_csv(baseUri+\"bad-more.csv\", sep=\"|\", error_bad_lines=False, warn_bad_lines=True)\n",
    "badDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting `error_bad_lines` to `False`, the system raise a warning and avoid to read malformed lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Data Type Problem\n",
    "\n",
    "Let's go back to the file we used in [Lab 1](./notebooks/python/data-ingestion/structured-semi_structured/lab/bulk-lab1.ipynb).\n",
    "\n",
    "Instead of using `Int64` pandas array data type, the problem with the `NaN` value and the numpy integer data type can be solved using pandas `converter` (see `read_csv` [doc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html))\n",
    "\n",
    "Let's reproduce the problem..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "\n",
    "dtp = { 'prev_id': np.int64\n",
    "        , 'curr_id': np.int64\n",
    "        , 'n': np.int64\n",
    "        , 'prev_title': np.string_\n",
    "        , 'curr_title': np.string_\n",
    "        , 'type': np.string_\n",
    "    }\n",
    "\n",
    "#pyCsvPath = baseUri + \"2015_02_clickstream.csv\"\n",
    "filePath = baseUri + \"good.csv\"\n",
    "\n",
    "# During the pandas reading we manage malformed lines\n",
    "df = pandas.read_csv(filePath, sep=\"|\", dtype=dtp)\n",
    "\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and solve it with converters.\n",
    "\n",
    "Our converter will use a `lambda function` ([info](https://en.wikipedia.org/wiki/Anonymous_function#Python) and [more info](05-Lambda-Expressions-Map-and-Filter.ipynb)) to cast to `numpy.int64` the value in the column `prev_id` if it is not `NaN`, 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtp = {'curr_id': np.int64\n",
    "       , 'n': np.int64\n",
    "       , 'prev_title': np.string_\n",
    "       , 'curr_title': np.string_\n",
    "       , 'type': np.string_\n",
    "       }\n",
    "\n",
    "#pyCsvPath = baseUri + \"2015_02_clickstream.csv\"\n",
    "filePath = baseUri + \"good.csv\"\n",
    "\n",
    "# During the pandas reading we manage malformed lines\n",
    "df = pandas.read_csv(\n",
    "    filePath\n",
    "    , sep=\"|\"\n",
    "    , dtype=dtp\n",
    "    , converters={'prev_id': lambda x: np.int64(0) if not x else np.int64(x)}\n",
    "    )\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "> If converters are specified, they will be applied INSTEAD of dtype conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**: is this a good solution?\n",
    "\n",
    "`prev_id` and `curr_id` are identifier. Shall we invent identifiers?\n",
    "\n",
    "Moreover, we are identifying with `0` several different values in the columns `prev_title` and `curr_title`. While technically we solved the problem, from a business perspective we did not.\n",
    "\n",
    "To address this common problem, also `int` shall we nullable, [Pandas fixed this problem in version 1.0.0](https://pandas.pydata.org/pandas-docs/stable/user_guide/integer_na.html#nullable-integer-data-type)\n",
    "\n",
    "Therefore, the correct solution is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtp = {\n",
    "    'prev_id': \"Int64\"\n",
    "    , 'curr_id': \"Int64\"\n",
    "    , 'n': np.int64\n",
    "    , 'prev_title': np.string_\n",
    "    , 'curr_title': np.string_\n",
    "    , 'type': np.string_\n",
    "}\n",
    "\n",
    "#pyCsvPath = baseUri + \"2015_02_clickstream.csv\"\n",
    "filePath = baseUri + \"good.csv\"\n",
    "\n",
    "# During the pandas reading we manage malformed lines\n",
    "df = pandas.read_csv(\n",
    "    filePath\n",
    "    , sep=\"|\"\n",
    "    , dtype=dtp\n",
    "    )\n",
    "\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ![Quantia Tiny Logo](https://www.quantiaconsulting.com/logos/quantia_logo_tiny.png) Quantia Consulting, srl. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "Data Ingestion - Lab - Solution",
  "notebookId": 1507370365633399
 },
 "nbformat": 4,
 "nbformat_minor": 4
}