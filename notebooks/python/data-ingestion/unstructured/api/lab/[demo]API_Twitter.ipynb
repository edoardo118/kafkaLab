{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 2px;\">\n",
    "  <img src=\"https://www.quantiaconsulting.com/logos/quantia_logo_orizz.png\" alt=\"Quantia Consulting\" style=\"width: 600px; height: 250px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter API Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Interact with [Twitter API](https://developer.twitter.com/en/docs.html). The main endpoints return tweets, users and followers. \n",
    "- It is necessary to generate an API key to obtain access to the endpoints.\n",
    "- You need to sign in on [Twitter](https://twitter.com) and then following this steps https://developer.twitter.com/en/docs/basics/authentication/guides/access-tokens.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API keys and tokens are needed to initialize Python Twitter Wrapper ([tweepy](https://tweepy.readthedocs.io/en/3.7.0/api.html)). It is a best practice to store the keys in a separated **configuration file** that should be kept secret and not shared (e.g.: on GitHub)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "cred = { \"consumer_key\" : \"\",\n",
    "         \"consumer_secret\" : \"\",\n",
    "         \"access_token\" : \"\",\n",
    "         \"access_token_secret\" : \"\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "consumer_key = cred['consumer_key']\n",
    "consumer_secret = cred['consumer_secret']\n",
    "access_token = cred['access_token']\n",
    "access_token_secret = cred['access_token_secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "twitter = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Get last N_MAX tweets of a specific user and store them in MongoDB collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def save_tweet(data):\n",
    "    tw = {}\n",
    "    tw['id_post'] = tweet.id\n",
    "    tw['username'] = tweet.user.screen_name\n",
    "\n",
    "    if tweet.coordinates is not None:\n",
    "        coor = tweet.coordinates['coordinates']\n",
    "        lat = coor[1]\n",
    "        lng = coor[0]\n",
    "        tw['lat'] = lat\n",
    "        tw['long'] = lng\n",
    "    else:\n",
    "        lat = None\n",
    "        lng = None\n",
    "\n",
    "    if tweet.place is not None:\n",
    "        place = tweet.place.name\n",
    "        tw['place'] = place\n",
    "    else:\n",
    "        place = None\n",
    "\n",
    "    tw['text'] = tweet.full_text\n",
    "    tw['timestamp'] = tweet.created_at\n",
    "    tw['retweets'] = tweet.retweet_count\n",
    "    tw['likes'] = tweet.favorite_count\n",
    "    tw['lang'] = tweet.lang\n",
    "    \n",
    "    return tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "N_MAX = 100\n",
    "username = 'polimi'\n",
    "\n",
    "tweets_df = pd.DataFrame(columns=['id_post','username','lat', 'long', 'place','text','timestamp','retweets','likes','lang'])\n",
    "for tweet in tweepy.Cursor(twitter.user_timeline, screen_name=username, tweet_mode='extended').items(N_MAX):\n",
    "    tw_row = save_tweet(tweet)\n",
    "    tweets_df = tweets_df.append(tw_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Retrieve user account information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = twitter.get_user(screen_name = username)\n",
    "\n",
    "print u._json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Save **follow** relationship. \n",
    "\n",
    "This is the most expensive operation, since number of followers can be extremely large. For this reason, we need to define a function to handle **API rate limits**: over a certain number of requests, that depends on resource, the API stops for **15 minutes** (more details [here](https://developer.twitter.com/en/docs/basics/rate-limits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def limit_handled(cursor):\n",
    "    while True:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            yield cursor.next()\n",
    "            \n",
    "        except tweepy.RateLimitError:\n",
    "            print ('API Rate Limit exceeded. Waiting...')\n",
    "            \n",
    "            # wait for 15 minutes to reset the API timeout\n",
    "            time.sleep(15 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "follow = pd.DataFrame(columns=['id_following', 'id_followed'])\n",
    "\n",
    "id_user = u.id\n",
    "for follower in limit_handled(tweepy.Cursor(twitter.followers_ids, screen_name=username).items()):\n",
    "    follow = follow.append({'id_following': follower, 'id_followed': id_user}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "follow['id_following'] = follow['id_following'].astype(long)\n",
    "follow['id_followed'] = follow['id_followed'].astype(long)\n",
    "follow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# save data\n",
    "spark_df = spark.createDataFrame(follow)\n",
    "spark_df.write.mode(\"overwrite\").saveAsTable(\"default.{}_followers\".format(username))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ![Quantia Tiny Logo](https://www.quantiaconsulting.com/logos/quantia_logo_tiny.png) 2020 Quantia Consulting, srl. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
