{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 2px;\">\n",
    "  <img src=\"https://www.quantiaconsulting.com/logos/quantia_logo_orizz.png\" alt=\"Quantia Consulting\" style=\"width: 600px; height: 250px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Kafka Avro Producer \n",
    "\n",
    "**Technical Accomplishments:**\n",
    "- Start working with avro schema in Kafka\n",
    "- Introduce the class `AvroProducer`\n",
    "- Produce data for a Kafka avro topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Let's start importing libraries and creating useful variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import avro\n",
    "from confluent_kafka.avro import AvroProducer\n",
    "import time\n",
    "import qcutils\n",
    "\n",
    "servers=qcutils.read_config_value(\"kafka.server\") + \":\" + str(qcutils.read_config_value(\"kafka.port\"))\n",
    "\n",
    "sr_url=qcutils.read_config_value(\"kafka.schema_registry.url\")\n",
    "\n",
    "topic = ''\n",
    "\n",
    "qcutils.create_kafka_topic(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: in order to avoid conflicts during write operation, please name the topic as `<surname>-topic`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "Let's start importing libraries and creating useful variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avro Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_schema_str = \"\"\"\n",
    "{\n",
    "  \"namespace\": \"example.avro\",\n",
    "  \"type\": \"record\",\n",
    "  \"name\": \"PersonKey\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"name\",\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "value_schema_str = \"\"\"\n",
    "{\n",
    "  \"namespace\": \"example.avro\",\n",
    "  \"type\": \"record\",\n",
    "  \"name\": \"PersonValue\",\n",
    "  \"fields\": \n",
    "    [{\n",
    "      \"name\": \"age\",\n",
    "      \"type\": \"int\",\n",
    "      \"default\": 18\n",
    "    }]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "key_schema = avro.loads(key_schema_str)\n",
    "value_schema = avro.loads(value_schema_str)\n",
    "\n",
    "key = {\"name\": \"Abe\"}\n",
    "\n",
    "def cb(err, msg):\n",
    "    if err is not None:\n",
    "        print(\"Failed to deliver message: {}\".format(err))\n",
    "    else:\n",
    "        print(\"Produced record to topic {} partition [{}] @ offset {}\"\n",
    "              .format(msg.topic(), msg.partition(), msg.offset()))\n",
    "\n",
    "sr_url=qcutils.read_config_value(\"kafka.schema_registry.url\")\n",
    "\n",
    "producerconf = {\n",
    "        'bootstrap.servers': servers,\n",
    "        'schema.registry.url': sr_url\n",
    "    }\n",
    "        \n",
    "ap = AvroProducer(producerconf, default_key_schema=key_schema, default_value_schema=value_schema)\n",
    "\n",
    "for i in range(0, 100):\n",
    "    value = {\"age\": i}\n",
    "    ap.produce(topic=topic, value=value, key=key, key_schema=key_schema, value_schema=value_schema, callback=cb)\n",
    "    print(value)\n",
    "    ap.poll(0)\n",
    "    time.sleep(1)\n",
    "    \n",
    "ap.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avro Producer with Evolving Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import avro\n",
    "from confluent_kafka.avro import AvroProducer\n",
    "import time\n",
    "\n",
    "key_schema_str = \"\"\"\n",
    "{\n",
    "  \"namespace\": \"example.avro\",\n",
    "  \"type\": \"record\",\n",
    "  \"name\": \"PersonKey\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"name\",\n",
    "      \"type\": \"string\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "value_schema_str = \"\"\"\n",
    "{\n",
    "  \"namespace\": \"example.avro\",\n",
    "  \"type\": \"record\",\n",
    "  \"name\": \"PersonValue\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"name\",\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"age\",\n",
    "      \"type\": \"int\",\n",
    "      \"default\": 18\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"haircolor\",\n",
    "      \"type\": \"string\",\n",
    "      \"default\": \"black\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "key_schema = avro.loads(key_schema_str)\n",
    "value_schema = avro.loads(value_schema_str)\n",
    "\n",
    "key = {\"name\": \"Abe\"}\n",
    "\n",
    "def cb(err, msg):\n",
    "    if err is not None:\n",
    "        print(\"Failed to deliver message: {}\".format(err))\n",
    "    else:\n",
    "        print(\"Produced record to topic {} partition [{}] @ offset {}\"\n",
    "              .format(msg.topic(), msg.partition(), msg.offset()))\n",
    "\n",
    "producerconf = {\n",
    "        'bootstrap.servers': servers,\n",
    "        'schema.registry.url': sr_url\n",
    "    }\n",
    "        \n",
    "ap = AvroProducer(producerconf, default_key_schema=key_schema, default_value_schema=value_schema)\n",
    "\n",
    "for i in range(0, 100):\n",
    "    if i < 40:\n",
    "        hairColor = \"black\"\n",
    "    elif (i >=40 and i < 55):\n",
    "        hairColor = \"grizzled\"\n",
    "    else:\n",
    "        hairColor = \"white\"\n",
    "  \n",
    "    value = {\"name\": \"Abe\", \"age\": i, \"haircolor\": hairColor}\n",
    "    ap.produce(topic=topic, value=value, key=key, key_schema=key_schema, value_schema=value_schema, callback=cb)\n",
    "    print(value)\n",
    "    ap.poll(0)\n",
    "    time.sleep(1)\n",
    "\n",
    "ap.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** In order to add SASL security for the connection to the kafka broker, you need to add security configurations.\n",
    "\n",
    "```\n",
    "username=qcutils.read_config_value(\"kafka.access.key\")\n",
    "password=qcutils.read_config_value(\"kafka.access.secret\")\n",
    "\n",
    "sr_user_info=qcutils.read_config_value(\"kafka.schema_registry.key\") + \":\" + qcutils.read_config_value(\"kafka.schema_registry.secret\")\n",
    "\n",
    "producerconf = {\n",
    "        'bootstrap.servers': <servers>,\n",
    "        'sasl.mechanisms': 'PLAIN',\n",
    "        'security.protocol': 'SASL_SSL',\n",
    "        'sasl.username': <username>,\n",
    "        'sasl.password': <password>,\n",
    "        'schema.registry.url': sr_url,\n",
    "        'schema.registry.basic.auth.credentials.source': 'USER_INFO',\n",
    "        'schema.registry.basic.auth.user.info': <login-info>\n",
    "    }\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ![Quantia Tiny Logo](https://www.quantiaconsulting.com/logos/quantia_logo_tiny.png) 2020 Quantia Consulting, srl. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "avro-producer",
  "notebookId": 1507370365633616
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
