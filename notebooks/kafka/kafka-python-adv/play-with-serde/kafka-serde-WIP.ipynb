{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 2px;\">\n",
    "  <img src=\"https://www.quantiaconsulting.com/logos/quantia_logo_orizz.png\" alt=\"Quantia Consulting\" style=\"width: 600px; height: 250px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![Quantia Tiny Logo](https://www.quantiaconsulting.com/logos/quantia_logo_tiny.png) Kafka Consumption with Explicit Deserializer\n",
    "\n",
    "Consume the topic named `ratings`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ![Quantia Tiny Logo](https://www.quantiaconsulting.com/logos/quantia_logo_tiny.png) General Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaError\n",
    "from confluent_kafka import avro\n",
    "from confluent_kafka.avro import AvroConsumer\n",
    "from confluent_kafka.avro.serializer import SerializerError\n",
    "import json\n",
    "import qcutils\n",
    "import time\n",
    "\n",
    "servers=qcutils.read_config_value(\"kafka.server\") + \":\" + str(qcutils.read_config_value(\"kafka.port\"))\n",
    "sr_url=qcutils.read_config_value(\"kafka.schema_registry.url\")\n",
    "\n",
    "print(servers)\n",
    "print(sr_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ![Quantia Tiny Logo](https://www.quantiaconsulting.com/logos/quantia_logo_tiny.png) Avro Consumer (`ratings` Topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for schemas in the Schema Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import DeserializingConsumer\n",
    "from confluent_kafka.schema_registry import SchemaRegistryClient\n",
    "from confluent_kafka.schema_registry.avro import AvroDeserializer\n",
    "from confluent_kafka.serialization import StringDeserializer\n",
    "\n",
    "sr_conf = {'url': sr_url}\n",
    "schema_registry_client = SchemaRegistryClient(sr_conf)\n",
    "\n",
    "schema_registry_client.get_subjects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the latest version of the schema of your interest\n",
    "\n",
    "Note that, for each topic, the key and value schema are named as <topic-name>-key and <topic-name>-value.\n",
    "\n",
    "As usual, it is not mandatory to have the key schema for an avro topic. By default, the key for an avro topic is a String.\n",
    "    \n",
    "In particular, the `ratings` topic have the value schema ('ratings-value'), but not the key schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_schema = schema_registry_client.get_latest_version('ratings-value').schema.schema_str\n",
    "print(value_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's consume the topic using the right serializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'ratings'\n",
    "consumer_group = 'MB-CG'\n",
    "\n",
    "key_deserializer = StringDeserializer()\n",
    "value_deserializer = AvroDeserializer(schema_str=value_schema,schema_registry_client=schema_registry_client)\n",
    "\n",
    "\n",
    "consumer_conf = {'bootstrap.servers': servers,\n",
    "                 'key.deserializer': key_deserializer,\n",
    "                 'value.deserializer': value_deserializer,\n",
    "                 'group.id': consumer_group,\n",
    "                 'auto.offset.reset': 'latest'}\n",
    "\n",
    "c = DeserializingConsumer(consumer_conf)\n",
    "c.subscribe([topic])\n",
    "\n",
    "waiting = False\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        msg = c.poll(1.0)\n",
    "        if msg is None:\n",
    "            if waiting:\n",
    "                print(\".\",end =\" \")\n",
    "            else:\n",
    "                print(\"Waiting\",end =\" \")\n",
    "                waiting = True\n",
    "            continue\n",
    "        elif msg.error():\n",
    "            print('error: {}'.format(msg.error()))\n",
    "            waiting = False\n",
    "        else:\n",
    "            value = msg.value()\n",
    "            key = msg.key()\n",
    "            print(\"\\nConsumed record with key {} and value {}\".format(key, value))\n",
    "            waiting = False\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    c.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ![Quantia Tiny Logo](https://www.quantiaconsulting.com/logos/quantia_logo_tiny.png) 2020 Quantia Consulting, srl. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "name": "kafka-ingestion - part 2",
  "notebookId": 1507370365634686
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
