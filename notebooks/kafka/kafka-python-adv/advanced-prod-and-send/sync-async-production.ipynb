{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 2px;\">\n",
    "  <img src=\"https://www.quantiaconsulting.com/logos/quantia_logo_orizz.png\" alt=\"Quantia Consulting\" style=\"width: 600px; height: 250px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchronous and Asynchronous write\n",
    "\n",
    "The producer uses the `produce(...)` method to trigger the message production operation.\n",
    "\n",
    "The `produce(...)` method is asynchronous, it enques messages in an internal queue and gives back the control to the user.\n",
    "\n",
    "An internal thread will send the queued messages in order.\n",
    "\n",
    "A writing block can be:\n",
    "* asynchronous: the [poll([timeout])](https://docs.confluent.io/current/clients/confluent-kafka-python/index.html#confluent_kafka.Producer.poll) function asynchronously propagates the results of the produce operation to the callback function without blocking the operation flux.\n",
    "* synchronous: the [flush([timeout])](https://docs.confluent.io/current/clients/confluent-kafka-python/index.html#confluent_kafka.Producer.flush) function waits for all messages in the Producer queue to be delivered before release the control.\n",
    "\n",
    "Both `poll([timeout])` and `flush([timeout])` accept a float parameter named timeout. \n",
    "\n",
    "The timeout represents the `maximum time to block waiting for events expressed in seconds`. \n",
    "\n",
    "Both functions wait, at maximum, <timestamp> seconds before returning an error to the callback function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "Let's initialize a producer and test `poll([timeout])` and `flush([timeout])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer, KafkaError\n",
    "import json\n",
    "import qcutils\n",
    "import time\n",
    "\n",
    "servers=qcutils.read_config_value(\"kafka.server\") + \":\" + str(qcutils.read_config_value(\"kafka.port\"))\n",
    "\n",
    "topic = ''\n",
    "\n",
    "assert len(topic) > 0, \"In order to avoid conflicts during write operation, please name the topic as <surname>-topic\"\n",
    "\n",
    "qcutils.create_kafka_topic(topic)\n",
    "\n",
    "producerconf = {\n",
    "    'bootstrap.servers': servers\n",
    "}\n",
    "\n",
    "\n",
    "p = Producer(producerconf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronous Production\n",
    "\n",
    "In the previous notebooks we exploited the synchronous production via the `flush([timeout])` method.\n",
    "\n",
    "Typically, the synchronous writes can, effectively, limit throughput to the broker round trip time, but, in some cases, it can be really useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "    \n",
    "for n in range(15):\n",
    "    record_key = \"qc-key\"\n",
    "    record_value = json.dumps({'count': n})\n",
    "    print(\"Producing record: {}\\t{}\".format(record_key, record_value))\n",
    "    p.produce(topic, key=record_key, value=record_value)\n",
    "    p.flush(10)\n",
    "\n",
    "print(\"{} messages were produced to topic {}!\".format(n + 1, topic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, the `flush([timeout])` function of the Producer is called at each iteration.\n",
    "\n",
    "The `flush([timeout])` is a blocking operation and call it too often, the throughput may fall.\n",
    "\n",
    "Let's try to call it once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "    \n",
    "for n in range(15):\n",
    "    record_key = \"qc-key\"\n",
    "    record_value = json.dumps({'count': n})\n",
    "    print(\"Producing record: {}\\t{}\".format(record_key, record_value))\n",
    "    p.produce(topic, key=record_key, value=record_value)\n",
    "\n",
    "p.flush(10)\n",
    "\n",
    "print(\"{} messages were produced to topic {}!\".format(n + 1, topic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the main difference?\n",
    "\n",
    "Look at the **execution time**! It is an order of magnitude faster than before...\n",
    "\n",
    "If you need to wait the message delivery at each iteration, the throughput falls.\n",
    "\n",
    ".... But how can we check for the production report?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the production results (Callback Function)\n",
    "\n",
    "In order to receive notification of delivery success or failure, you can define a callback function and pass it as a parameter to the `produce(...)` function.\n",
    "\n",
    "Let's first try to check the production results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(\"Failed to deliver message: {}\".format(err))\n",
    "    else:\n",
    "        print(\"Produced record to topic {} partition [{}] @ offset {}\"\n",
    "              .format(msg.topic(), msg.partition(), msg.offset()))\n",
    "\n",
    "for n in range(15):\n",
    "    record_key = \"qc-key\"\n",
    "    record_value = json.dumps({'count': n})\n",
    "    print(\"Producing record: {}\\t{}\".format(record_key, record_value))\n",
    "    p.produce(topic, key=record_key, value=record_value, on_delivery=delivery_report)\n",
    "\n",
    "p.flush(1)\n",
    "\n",
    "print(\"{} messages were produced to topic {}!\".format(n + 1, topic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".... and what if we need to know the delivery report at each iteration with a comparable throughput??\n",
    "\n",
    "We need to produce asynchronously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous Production\n",
    "\n",
    "During the aynchronous write, we call the `poll([timeout])` function.\n",
    "\n",
    "The `poll([timeout])` function tell the system to wait up to `timeout` seconds for events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(\"Failed to deliver message: {}\".format(err))\n",
    "    else:\n",
    "        print(\"Produced record to topic {} partition [{}] @ offset {}\"\n",
    "              .format(msg.topic(), msg.partition(), msg.offset()))\n",
    "\n",
    "for n in range(15):\n",
    "    record_value = json.dumps({'count': n})\n",
    "    print(\"Producing record: {}\".format(record_value))\n",
    "    p.produce(topic, value=record_value, on_delivery=delivery_report)\n",
    "    p.poll(0)\n",
    "\n",
    "print(\"{} messages were produced to topic {}!\".format(n + 1, topic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see the report deliveries interlived to the production \"log\" with a comparable execution time (and consequently production throughput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Note and Good Practice\n",
    "\n",
    "\n",
    "### Poll and Flush together\n",
    "At the end of all the wtiting operations, even if we use the Asynchronous way, it is a good practice to call `flush()`.\n",
    "\n",
    "`flush()` should be called before shutting down the producer to ensure all outstanding/queued/in-flight messages are delivered.\n",
    "\n",
    "### Key Recall\n",
    "You must specify the message value during the production, but the key is not mandatory. If you don't specify any key, the system will automatically put `null` as message key. \n",
    "\n",
    "Specify a key represent a good practice. The message key could be useful during data preparation and data analysis phase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ![Quantia Tiny Logo](https://www.quantiaconsulting.com/logos/quantia_logo_tiny.png) 2020 Quantia Consulting, srl. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
