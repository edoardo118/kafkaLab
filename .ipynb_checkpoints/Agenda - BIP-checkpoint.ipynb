{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 2px;\">\n",
    "  <img src=\"https://www.quantiaconsulting.com/logos/quantia_logo_orizz.png\" alt=\"Quantia Consulting\" style=\"width: 600px; height: 250px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Spark\n",
    "\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "|**[Introduction and Overview](./notebooks/spark/intro/00-spark-overview.ipynb)** | Brief History and Overview of Spark |\n",
    "|**[Basics and RDD](./notebooks/spark/intro/01-touching-spark-part1.ipynb)** | Basics concepts in practice from RDD perspective |\n",
    "|**[Lab1](./notebooks/spark/intro/lab/01a-touching-spark-part1-lab.ipynb)** | Put at work what we've learnt on RDD |\n",
    "|**[DataFrame and Optimization](./notebooks/spark/intro/02-touching-spark-part2.ipynb)** | Basics concepts in practice from DataFrame perspective perspective |\n",
    "|**[Lab 2a](./notebooks/spark/intro/lab/02a-touching-spark-part2-lab.ipynb)** | Overview on Spark UI Jobs and Stages tabs  |\n",
    "|**[Lab2b](./notebooks/spark/intro/lab/02b-touching-spark-part2-lab.ipynb)** | Put at work what we've learnt on DataFrame |\n",
    "|**[Partitioning](./notebooks/spark/intro/03-touching-spark-part3.ipynb)** | Overview on Partitioning |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion - Unstructured\n",
    "\n",
    "##### API\n",
    "\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "|**Basic Concepts** | *Basic concepts on API and service-based architecture approaches, principles, advantages and roles of API in modern distributed data-driven architectures* |\n",
    "|**Extracting Data from Social Media** - [demo](./notebooks/python/data-ingestion/unstructured/api/lab/[demo]API_Twitter.ipynb), [hands-on](./notebooks/python/data-ingestion/unstructured/api/lab/[hands-on]API_Twitter.ipynb), [solution](./notebooks/python/data-ingestion/unstructured/api/lab-solutions/[solution]API_Twitter.ipynb)| *Extract tweets of given users using [Twitter API](https://developer.twitter.com/en/docs.html)* |\n",
    "|**Extracting Weather Data** - [demo](./notebooks/python/data-ingestion/unstructured/api/lab/[demo]API_Weather.ipynb), [hands-on](./notebooks/python/data-ingestion/unstructured/api/lab/[hands-on]API_Weather.ipynb), [solution](./notebooks/python/data-ingestion/unstructured/api/ab-solutions/[solution]API_Weather.ipynb)| *Extract current weather and weather forecasting using [OpenWeatherMap API](https://openweathermap.org/)* |\n",
    "|**Extracting Geographical Data** - [demo](./notebooks/python/data-ingestion/unstructured/api/lab/[demo]API_OpenStreetMap.ipynb), [hands-on](./notebooks/python/data-ingestion/unstructured/api/lab/[hands-on]API_OpenStreetMap.ipynb), [solution](./notebooks/python/data-ingestion/unstructured/api/ab-solutions/[solution]API_OpenStreetMap.ipynb)| *Extract geolocated data from [OpenStreetMap API](https://wiki.openstreetmap.org/wiki/API)* |\n",
    "\n",
    "-------------\n",
    "\n",
    "\n",
    "##### Scraping\n",
    "\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "|**Basic Concepts** | *Importance and role of Web data, structure of HTML documents and DOM trees, basics of XPATH and purposes and logics behind Javascript* |\n",
    "|**Introduction to Scraping Techniques** | *What is scraping and why it is needed, basic tools (curl and requests), implementing a Python scraper and python libraries for scraping (Selenium and BeautifulSoup)* |\n",
    "|**Lab** - [TripAdvisor POIs](./notebooks/python/data-ingestion/unstructured/scraping/Exercises/SCRIPT/ex1_ta_places.py) - [solution](./notebooks/python/data-ingestion/unstructured/scraping/Exercises/SOLVED/ex1_gm_places.py) | Getting data from a static page |\n",
    "|**Lab** - [TripAdvisor reviews - 1](./notebooks/python/data-ingestion/unstructured/scraping/Exercises/SCRIPT/ex2a_ta_places_review.py), [TripAdvisor reviews - 2](./notebooks/python/data-ingestion/unstructured/scraping/Exercises/SCRIPT/ex2b_ta_places_review.py) - [solution](./notebooks/python/data-ingestion/unstructured/scraping/Exercises/SOLVED/ex2_gm_places_review.py)| Getting data from multiple pages |\n",
    "|**Lab** - [Filtering, scrolling and waiting](./notebooks/python/data-ingestion/unstructured/scraping/Exercises/SCRIPT/ex3_ta_places_review_filters.py) - [solution](./notebooks/python/data-ingestion/unstructured/scraping/Exercises/SOLVED/ex3_gm_places_review_filters.py)| Getting data from dynamic pages |\n",
    "|**Lab** - [Interact with search bar](./notebooks/python/data-ingestion/unstructured/scraping/Exercises/SCRIPT/ex4_ta_search.py) - [solution](./notebooks/python/data-ingestion/unstructured/scraping/Exercises/SOLVED/ex4_gm_search.py)| Getting data from unknown pages |\n",
    "\n",
    "\n",
    "-------------\n",
    "\n",
    "\n",
    "##### Nosql\n",
    "\n",
    "> Before using the following notebooks, please run the following command `pip install -r ~/materials/notebooks/nosql/requirements.txt` in a terminal window.\n",
    "\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "|**Neo4J** - [notebook](./notebooks/nosql/neo4j.ipynb)| *Deepen your understanding in Neo4J infrastructure* |\n",
    "|**MongoDB** - [notebook](./notebooks/nosql/mongodb.ipynb) | *Deepen your understanding in mongoDB infrastructure* |\n",
    "|**ElasticSearch** - [notebook](./notebooks/nosql/elasticsearch.ipynb) | *Deepen your understanding in Elastic Search infrastructure* |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion - Structured & Semi-Structured "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulk\n",
    "\n",
    "##### Basic concepts\n",
    "\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "|**Reading Data - Intro** - [python](./notebooks/python/data-ingestion/structured-semi_structured/bulk-intro.ipynb), [pyspark](./notebooks/spark/data-ingestion/bulk-intro.ipynb)         | *Overview of the reading functions in* ***pandas*** *and* ***pyspark*** |\n",
    "|**Reading Data - CSV** - [python](./notebooks/python/data-ingestion/structured-semi_structured/bulk-csv.ipynb), [pyspark](./notebooks/spark/data-ingestion/bulk-csv.ipynb)         | *Reading **CSV** Data, and Manage Data Schemas* |\n",
    "|**Reading Data - Parquet** - [python](./notebooks/python/data-ingestion/structured-semi_structured/bulk-parquet.ipynb), [pyspark](./notebooks/spark/data-ingestion/bulk-parquet.ipynb) | *Reading **Parquet** the well-known splittable columnar file format.* |\n",
    "|**Writing Data** - [pyspark](./notebooks/spark/data-ingestion/bulk-writing.ipynb), [python](./notebooks/python/data-ingestion/structured-semi_structured/bulk-writing.ipynb) | *Writing files* |\n",
    "|**Lab1** - Reading and Writing Data in [python](./notebooks/python/data-ingestion/structured-semi_structured/lab/bulk-lab1.ipynb) and [pyspark](./notebooks/spark/data-ingestion/lab/bulk-lab1.ipynb) - 1 - [python-solution](./notebooks/python/data-ingestion/structured-semi_structured/lab-solutions/bulk-lab1-solution.ipynb) and [pyspark-solution](./notebooks/spark/data-ingestion/lab-solutions/bulk-lab1-solution.ipynb)        | *Putting to practice what we just learned* |\n",
    "|**Lab2** - Reading and Writing Data in [python](./notebooks/python/data-ingestion/structured-semi_structured/lab/bulk-lab2.ipynb) and [pyspark](./notebooks/spark/data-ingestion/lab/bulk-lab2.ipynb) - 2 - [python-solution](./notebooks/python/data-ingestion/structured-semi_structured/lab-solutions/bulk-lab2-solution.ipynb) and [pyspark-solution](./notebooks/spark/data-ingestion/lab-solutions/bulk-lab2-solution.ipynb)        | *Putting to practice what we just learned* |\n",
    "\n",
    "\n",
    "##### Advanced concepts\n",
    "\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "|**Reading Data - Excel** - [python](./notebooks/python/data-ingestion/structured-semi_structured/bulk-excel.ipynb)        | *Reading xls/xlsx files with multiple sheets* |\n",
    "|**Reading Data - Relational Data** - [pyspark](./notebooks/spark/data-ingestion/bulk-jdbc.ipynb), [python](./notebooks/python/data-ingestion/structured-semi_structured/bulk-relational.ipynb) | *Reading relational data from external realational sources* | \n",
    "|**Reading Data - JSON** - [pyspark](./notebooks/spark/data-ingestion/bulk-json.ipynb), [python](materials/notebooks/python/data-ingestion/structured-semi_structured/bulk-json.ipynb)      | *Complex Data Types, JSON-Lines & Multi-Line JSON* |\n",
    "|**Reading Data - Text** - [pyspark](./notebooks/spark/data-ingestion/bulk-text.ipynb)       | *Simple Text Files* |\n",
    "|**Reading Data - Tables** - [pyspark](./notebooks/spark/data-ingestion/bulk-tables.ipynb)       | *Write and Read data on local db* |\n",
    "\n",
    "##### Summary\n",
    "\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "|**Reading Data - Summary** - [python](./notebooks/python/data-ingestion/structured-semi_structured/bulk-summary.ipynb), [pyspark](./notebooks/spark/data-ingestion/bulk-summary.ipynb) | *Review of the various readers and data sources* |\n",
    "|**Challenge** - [A realistic case of ingestion for Data Exploration](./notebooks/spark/data-ingestion/lab/bulk-challenge.ipynb) - [solution](./notebooks/spark/data-ingestion/lab-solutions/bulk-challenge-solution.ipynb) | *Challenge yourself by putting in practice what we just learned*|\n",
    "\n",
    "##### Extra\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "|**Handle Corrupted Records** [python](./notebooks/python/data-ingestion/structured-semi_structured/bulk-py-handle-corrupt-bad-record.ipynb), [pyspark](./notebooks/spark/data-ingestion/bulk-ps-handle-corrupt-bad-record.ipynb) | *How to handle bad and corrupted records while reading files* |\n",
    "\n",
    "##### Bulk Data Ingestion Challenge\n",
    "\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "|**Challenge** - [general-instructions](./notebooks/data-ingestion-challenge/challenge/general-instructions.ipynb) - [solution](./notebooks/data-ingestion-challenge/challenge-solution/general-instructions.ipynb) | *Challenge yourself by putting in practice what we just learned*|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous\n",
    "\n",
    "##### Basic concepts\n",
    "\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "|**Intro**        | *Latency vs. throughput vs size* |\n",
    "|**[Playing with terminal](./notebooks/kafka/kafka-terminal/exploring-with-terminal-1.ipynb)** | *Experience producers, consumers and zookeeper using simple messages* |\n",
    "|**[Playing more with terminal](./notebooks/kafka/kafka-terminal/exploring-with-terminal-2.ipynb)** | *Experience producers, consumers and zookeeper using <key,value> pair messages* |\n",
    "|**[Simple producer](./notebooks/kafka/kafka-python/plain/simple-producer.ipynb)** | *Write your first python producer and see the results on a console consumer* |\n",
    "|**[Simple consumer](./notebooks/kafka/kafka-python/plain/simple-consumer.ipynb)** | *Explore message encoding and decoding writing your first python consumer* |\n",
    "|**JSON [producer](./notebooks/kafka/kafka-python/plain/json-producer.ipynb) and [consumer](./notebooks/kafka/kafka-python/plain/json-consumer.ipynb)** | *Learn how to easily produce and consume (semi-)structured messages using JSON* |\n",
    "|**JSON Challenge** | *Put in practice what you learnt by creating a pair kafka [producer](./notebooks/kafka/lab/challenge-json-producer.ipynb) and [consumer](./notebooks/kafka/lab/challenge-json-consumer.ipynb) to produce and consume messages describing cars in JSON format* - [producer-solution](./notebooks/kafka/lab-solutions/challenge-json-producer-solution.ipynb), [consumer-solution](./notebooks/kafka/lab-solutions/challenge-json-consumer-solution.ipynb)|\n",
    "\n",
    "##### Avro & Kafka\n",
    "\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "|**[Simple Avro producer](./notebooks/kafka/kafka-python/avro/simple-avro-producer.ipynb)** | *Write your first avro producer* |\n",
    "|**[Simple Avro consumer](./notebooks/kafka/kafka-python/avro/simple-avro-consumer.ipynb)** | *Write your first avro consumer* |\n",
    "|**[Back to Simple Avro producer](./notebooks/kafka/kafka-python/avro/simple-avro-producer.ipynb)** | *Understand Avro schema evolution* |\n",
    "|**Avro Lab** | *Put in practice what you learnt about Avro & Kafka creating an [Avro producer](./notebooks/kafka/lab/lab-avro-producer.ipynb) and an [Avro consumer](./notebooks/kafka/lab/lab-avro-consumer.ipynb) to produce and consume messages describing cars in Avro format*  - [Avro producer solution](./notebooks/kafka/lab-solutions/lab-avro-producer-solution.ipynb), [Avro consumer Solution](./notebooks/kafka/lab-solutions/lab-avro-consumer-solution.ipynb) |\n",
    "|**Avro Challenge** | *Show yourself that you master Avro by creating an [Avro producer](./notebooks/kafka/lab/challenge-avro-producer.ipynb) and an [Avro consumer](./notebooks/kafka/lab/challenge-avro-consumer.ipynb) to produce and consume messages describing a card deck*  - [Avro producer solution](./notebooks/kafka/lab-solutions/challenge-avro-producer-solution.ipynb), [Avro consumer Solution](./notebooks/kafka/lab-solutions/challenge-avro-consumer-solution.ipynb) |\n",
    "\n",
    "##### When do producers actually send messages?\n",
    "\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "|**Intro** | *Understand asynchronous and parallel production* |\n",
    "|**[Advanced Production](./notebooks/kafka/kafka-python-adv/advanced-prod-and-send/sync-async-production.ipynb)** | *Experience the difference between synchronous and asynchronous production* |\n",
    "|**Sync JSON producer Lab** | *Deepen your understanding on `flush()` playing with a [synchronous JSON producer](./notebooks/kafka/lab/lab-sync-json-producer.ipynb) and a [JSON consumer](./notebooks/kafka/lab/lab-sync-json-consumer.ipynb)*   - [Synchronous JSON producer solution](./notebooks/kafka/lab-solutions/lab-sync-json-producer-solution.ipynb), [JSON consumer solution](./notebooks/kafka/lab-solutions/lab-sync-json-producer-solution.ipynb) |\n",
    "|**Async Avro producer Challenge** | *Show yourself that you master asynchronous production by creating an [Async Avro producer](./notebooks/kafka/lab/challenge-async-avro-producer.ipynb) and an [Avro consumer](./notebooks/kafka/lab/challenge-async-avro-consumer.ipynb)* - [Async Avro producer solution](./notebooks/kafka/lab-solutions/challenge-async-avro-producer-solution.ipynb) and [Avro consumer solution](./notebooks/kafka/lab-solutions/challenge-avro-consumer-solution.ipynb)|\n",
    "|**Discussion** | *[Balancing between high throughput and low latency](./notebooks/kafka/kafka-python-adv/advanced-prod-and-send/send-tuning.ipynb)* |\n",
    "\n",
    "#### Scalable countinous production & consumption\n",
    "\n",
    "| Topic | Description |\n",
    "|-------|-------------|\n",
    "|**Demo on parallel production/consumption** | *Experience how Topic partioning and Consumer Groups enable Scalable countinous production & consumption using a [producer](./notebooks/kafka/kafka-python-adv/scaling-out/producer-on-multi-partions.ipynb) and three consumers ([1](kafka-python-adv/scaling-out/consumer-1-for-multi-partions.ipynb), [2](./notebooks/kafka/kafka-python-adv/scaling-out/consumer-2-for-multi-partions.ipynb) & [3](./notebooks/kafka/kafka-python-adv/scaling-out/consumer-3-for-multi-partions.ipynb))* |\n",
    "|**Discussion** | *How would you design a Kafka-based continuous receipt ingestion solution for a large retail chain with 1.000s of stores and 100.000s SKUs?* |\n",
    "|**[Spark Structure Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)** | *Learn about the popular streaming extension of Spark* |\n",
    "|**Pyspark parallel Kafka-consumption** | *Experience how to build a pyspark Kafka consumer for [textual](./notebooks/kafka/kafka-pyspark/consuming-from-plain-kafka.ipynb) and [Avro](./notebooks/kafka/kafka-pyspark/consuming-from-avro-kafka.ipynb) Kafka topics* |\n",
    "|**Lab**| *Deepen your understanding on pyspark parallel Kafka-consumption writing a [pyspark notebook](./notebooks/kafka/lab/lab-pyspark.ipynb) that consumes a textual kafka topic* - [solution](./notebooks/kafka/lab-solutions/lab-pyspark-solution.ipynb) |\n",
    "|**Challenge**| *Show yourself that you master pyspark parallel Kafka-consumption writing a [pyspark notebook](./notebooks/kafka/lab/challenge-pyspark.ipynb) that consumes a real Avro topic* - [solution](./notebooks/kafka/lab-solutions/challenge-pyspark-solution.ipynb)|\n",
    "|**Fault tollerance** | Deepen your understanding on scalable continuos ingestion understading fault tollerance |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Cloud Platform\n",
    "| Topic                          | Description                          |\n",
    "|--------------------------------|--------------------------------------|\n",
    "| **GCP - Theory** - [md](./notebooks/google-cloud/1-GCP-theory.md) | *Overview of theoretical foundations of Google Cloud Platform*|\n",
    "| **GCP - Hands-on Setup** - [md](./notebooks/google-cloud/2-GCP-handson-setup.md) | *General overview of needed set-up for the hands-on sessions*|\n",
    "| **GCP - Hands-on Storage** - [md](./notebooks/google-cloud/3-GCP-handson-storage.md) | *Guided hands-on on Google Cloud Platform Storage (with exercise)*|\n",
    "| **GCP - Hands-on BigQuery** - [md](./notebooks/google-cloud/4-GCP-handson-bigquery.md) | *Guided hands-on on Google Cloud Platform BigQuery (with exercise)*|\n",
    "| **GCP - Hands-on PubSub** - [md](./notebooks/google-cloud/5-GCP-handson-PubSub.md) | *Guided hands-on on Google Cloud Platform PubSub system (with exercise)*|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ![Quantia Tiny Logo](https://www.quantiaconsulting.com/logos/quantia_logo_tiny.png) 2020 Quantia Consulting, srl. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "name": "Agenda - Data Ingestion",
  "notebookId": 1507370365633581
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
